/**
 * WasmBridge - Bridge between TypeScript and Rust WASM decoder
 *
 * Handles WASM module loading, video decoding, and frame management.
 * Supports multiple backends:
 * 1. FFmpeg.wasm - Universal format support (primary for non-MP4 files)
 * 2. WebCodecs API - Hardware-accelerated decoding for supported formats
 * 3. WASM module - Fallback decoder
 */

import { WebCodecsDecoder, type DecodedVideoFrame, type DecodedAudioData } from './WebCodecsDecoder';
import { Demuxer, type VideoSample, type AudioSample } from './Demuxer';
import { FFmpegDecoder, type TranscodeProgress } from './FFmpegDecoder';
import { createLogger } from '../utils/debug';
import { FastQueue } from '../utils/FastQueue';

const log = createLogger({ module: 'WasmBridge' });

/**
 * Video metadata
 */
export interface VideoMetadata {
  width: number;
  height: number;
  duration: number;
  frameRate: number;
  codec: string;
}

/**
 * Decoded video frame (compatible with both WASM and WebCodecs)
 */
export interface DecodedFrame {
  data: Uint8Array;
  width: number;
  height: number;
  timestamp: number;
  keyframe: boolean;
}

/**
 * Legacy alias for backwards compatibility
 * @deprecated Use DecodedFrame instead
 */
export type VideoFrame = DecodedFrame;

/**
 * Decoder backend type
 */
export type DecoderBackend = 'wasm' | 'webcodecs' | 'ffmpeg' | 'none';

/**
 * Transcoding progress callback
 */
export type TranscodeProgressCallback = (progress: TranscodeProgress) => void;

/**
 * WASM module interface (generated by wasm-pack)
 */
interface WasmModule {
  init: () => Promise<void>;
  load_video: (data: Uint8Array) => boolean;
  get_metadata: () => VideoMetadata | null;
  decode_frame: () => DecodedFrame | null;
  seek: (timestamp: number) => boolean;
  flush: () => void;
  free: () => void;
}

/**
 * WasmBridge configuration
 */
export interface WasmBridgeConfig {
  /** Callback for FFmpeg transcoding progress */
  onTranscodeProgress?: TranscodeProgressCallback;
  /** Callback for FFmpeg log messages */
  onFFmpegLog?: (message: string) => void;
  /** Preferred backend order (tries in order until one works) */
  preferredBackends?: DecoderBackend[];
  /** Force FFmpeg for all files (useful for testing) */
  forceFFmpeg?: boolean;
  /** Audio player for playback (optional, for audio sample playback) */
  audioPlayer?: import('./AudioPlayer').AudioPlayer;
}

/**
 * WasmBridge class
 *
 * Universal video decoder with multiple backend support:
 * - FFmpeg.wasm: Handles any video format through transcoding
 * - WebCodecs: Hardware-accelerated decoding for MP4/H.264
 * - WASM: Custom Rust-based decoder fallback
 */
export class WasmBridge {
  private wasmModule: WasmModule | null = null;
  private webCodecsDecoder: WebCodecsDecoder | null = null;
  private ffmpegDecoder: FFmpegDecoder | null = null;
  private demuxer: Demuxer | null = null;
  private initialized: boolean = false;
  private metadata: VideoMetadata | null = null;
  private backend: DecoderBackend = 'none';
  private videoSampleQueue = new FastQueue<VideoSample>(128);
  private audioSampleQueue = new FastQueue<AudioSample>(128);
  private webCodecsFrameQueue = new FastQueue<DecodedFrame>(32);
  // Persistent storage for all samples (for seeking)
  private allVideoSamples: VideoSample[] = [];
  private allAudioSamples: AudioSample[] = [];
  // Seek target timestamp in SECONDS - frames before this are skipped during playback
  private seekTargetTimestamp: number = 0;
  private readonly config: WasmBridgeConfig;
  private transcodedBuffer: ArrayBuffer | null = null;
  private needsKeyframe: boolean = true; // VideoDecoder requires keyframe after configure/flush
  private seekGeneration: number = 0;

  constructor(config: WasmBridgeConfig = {}) {
    this.config = config;
  }

  /**
   * Initialize the decoder
   *
   * Initializes all available backends for runtime selection:
   * - FFmpeg.wasm for universal format support
   * - WebCodecs for hardware-accelerated decoding
   * - WASM module as fallback
   */
  async init(): Promise<void> {
    if (this.initialized) {
      return;
    }

    const errors: string[] = [];

    // Initialize FFmpeg.wasm (for universal format support)
    if (FFmpegDecoder.isSupported()) {
      try {
        const ffmpegConfig: {
          onProgress?: (progress: TranscodeProgress) => void;
          onLog?: (message: string) => void;
          onError?: (error: Error) => void;
        } = {
          onError: (error: Error) => {
            log.error('FFmpeg decoder error:', error);
          },
        };

        if (this.config.onTranscodeProgress) {
          ffmpegConfig.onProgress = this.config.onTranscodeProgress;
        }
        if (this.config.onFFmpegLog) {
          ffmpegConfig.onLog = this.config.onFFmpegLog;
        }

        this.ffmpegDecoder = new FFmpegDecoder(ffmpegConfig);

        const ffmpegSuccess = await this.ffmpegDecoder.init();
        if (ffmpegSuccess) {
          log.info('FFmpeg.wasm backend initialized');
        } else {
          this.ffmpegDecoder = null;
          errors.push('FFmpeg.wasm initialization failed');
        }
      } catch (error) {
        this.ffmpegDecoder = null;
        errors.push(`FFmpeg.wasm: ${error instanceof Error ? error.message : String(error)}`);
      }
    } else {
      errors.push(`FFmpeg.wasm: ${FFmpegDecoder.getUnsupportedMessage()}`);
    }

    // Initialize WebCodecs (for MP4/H.264 hardware acceleration)
    if (WebCodecsDecoder.isSupported() && WebCodecsDecoder.isSecureContext()) {
      this.webCodecsDecoder = new WebCodecsDecoder({
        onVideoFrame: (frame: DecodedVideoFrame) => {
          this.handleWebCodecsVideoFrame(frame);
        },
        onAudioData: (audioData) => {
          this.handleWebCodecsAudioData(audioData);
        },
        onError: (error: Error) => {
          log.error('WebCodecs decoder error:', error);
        },
      });

      const success = await this.webCodecsDecoder.init();
      if (success) {
        this.demuxer = new Demuxer({
          onVideoSample: (sample: VideoSample) => {
            this.videoSampleQueue.push(sample);
          },
          onAudioSample: (sample: AudioSample) => {
            this.audioSampleQueue.push(sample);
          },
        });
        this.demuxer.init();
        log.info('WebCodecs backend initialized');
      } else {
        this.webCodecsDecoder = null;
        errors.push('WebCodecs initialization failed');
      }
    } else {
      errors.push(`WebCodecs: ${WebCodecsDecoder.getUnsupportedMessage()}`);
    }

    // Initialize WASM module fallback
    try {
      const wasm = await import('../../pkg/player_core');
      await wasm.default();
      this.wasmModule = wasm as unknown as WasmModule;
      log.info('WASM backend initialized');
    } catch (error) {
      errors.push(`WASM: ${error instanceof Error ? error.message : String(error)}`);
    }

    // Determine primary backend
    if (this.config.forceFFmpeg && this.ffmpegDecoder) {
      this.backend = 'ffmpeg';
    } else if (this.webCodecsDecoder) {
      this.backend = 'webcodecs';
    } else if (this.ffmpegDecoder) {
      this.backend = 'ffmpeg';
    } else if (this.wasmModule) {
      this.backend = 'wasm';
    }

    if (this.backend === 'none') {
      throw new Error(`No video decoder available. Errors: ${errors.join('; ')}`);
    }

    this.initialized = true;
    log.info('Primary decoder backend:', this.backend);
  }

  /**
   * Handle decoded video frame from WebCodecs
   */
  private handleWebCodecsVideoFrame(decodedFrame: DecodedVideoFrame): void {
    const frame = decodedFrame.frame;
    const width = frame.displayWidth;
    const height = frame.displayHeight;

    // Create RGBA buffer
    const data = new Uint8Array(width * height * 4);

    // Capture current generation to detect stale frames after async copyTo
    const generation = this.seekGeneration;

    // Copy frame data to buffer (async operation)
    frame
      .copyTo(data, {
        format: 'RGBA',
      })
      .then(() => {
        // Discard frame if a seek occurred during copyTo
        if (generation !== this.seekGeneration) {
          return;
        }
        this.webCodecsFrameQueue.push({
          data,
          width,
          height,
          timestamp: decodedFrame.timestamp / 1_000_000, // Convert microseconds to seconds
          keyframe: decodedFrame.keyframe,
        });
      })
      .catch((error: Error) => {
        log.error('Failed to copy frame data:', error);
      })
      .finally(() => {
        // Release the VideoFrame
        frame.close();
      });
  }

  /**
   * Handle decoded audio data from WebCodecs
   */
  private handleWebCodecsAudioData(decodedAudio: DecodedAudioData): void {
    const audioData = decodedAudio.data;

    // If no audio player configured, skip audio playback
    if (!this.config.audioPlayer) {
      audioData.close();
      return;
    }

    try {
      // Extract audio samples to Float32Array
      const numberOfFrames = audioData.numberOfFrames;
      const numberOfChannels = audioData.numberOfChannels;
      const sampleRate = audioData.sampleRate;

      // Allocate buffer for interleaved audio data
      const audioBuffer = new Float32Array(numberOfFrames * numberOfChannels);

      // Copy audio data (WebCodecs AudioData uses planar format by default)
      // We need to copy each channel and interleave
      for (let channel = 0; channel < numberOfChannels; channel++) {
        const channelData = new Float32Array(numberOfFrames);

        // Copy planar channel data
        audioData.copyTo(channelData, {
          planeIndex: channel,
          format: 'f32-planar',
        });

        // Interleave into output buffer
        for (let frame = 0; frame < numberOfFrames; frame++) {
          audioBuffer[frame * numberOfChannels + channel] = channelData[frame]!;
        }
      }

      // Play audio buffer (AudioPlayer handles sequential scheduling automatically)
      this.config.audioPlayer.playBuffer(audioBuffer);

      log.debug('Audio decoded:', numberOfFrames, 'frames,', numberOfChannels, 'ch,', sampleRate, 'Hz');
    } catch (error) {
      log.error('Failed to play audio data:', error);
    } finally {
      // Always close AudioData to free resources
      audioData.close();
    }
  }

  /**
   * Get the current decoder backend
   */
  getBackend(): DecoderBackend {
    return this.backend;
  }

  /**
   * Check if WASM module is initialized
   */
  isInitialized(): boolean {
    return this.initialized;
  }

  /**
   * Check if a file needs FFmpeg transcoding
   */
  private needsFFmpegTranscode(source: string | ArrayBuffer | File): boolean {
    if (this.config.forceFFmpeg) {
      return true;
    }

    let filename: string;
    if (source instanceof File) {
      filename = source.name;
    } else if (typeof source === 'string') {
      filename = source;
    } else {
      // ArrayBuffer - assume it might need transcoding if we can't determine format
      return false;
    }

    const ext = filename.split('.').pop()?.toLowerCase() ?? '';

    // Formats that WebCodecs/Demuxer can handle natively
    const nativeFormats = ['mp4', 'm4v', 'mov'];

    // If it's not a native format and FFmpeg is available, use FFmpeg
    return !nativeFormats.includes(ext) && this.ffmpegDecoder !== null;
  }

  /**
   * Load a video file
   *
   * Automatically selects the appropriate backend:
   * - FFmpeg for non-MP4 formats (MKV, AVI, WebM, etc.)
   * - WebCodecs for MP4/H.264 files
   * - WASM as fallback
   */
  async loadVideo(source: string | ArrayBuffer | File): Promise<void> {
    this.ensureInitialized();

    // Check if FFmpeg transcoding is needed
    if (this.needsFFmpegTranscode(source)) {
      await this.loadVideoWithFFmpeg(source);
      return;
    }

    let data: Uint8Array;
    let buffer: ArrayBuffer;

    if (source instanceof File) {
      buffer = await source.arrayBuffer();
      data = new Uint8Array(buffer);
    } else if (typeof source === 'string') {
      // Fetch video from URL
      const response = await fetch(source);
      if (!response.ok) {
        throw new Error(`Failed to fetch video: ${response.statusText}`);
      }
      buffer = await response.arrayBuffer();
      data = new Uint8Array(buffer);
    } else {
      buffer = source;
      data = new Uint8Array(source);
    }

    if (this.backend === 'wasm') {
      const success = this.wasmModule!.load_video(data);
      if (!success) {
        throw new Error('Failed to load video in WASM decoder');
      }
      this.metadata = this.wasmModule!.get_metadata();
    } else if (this.backend === 'webcodecs' || this.backend === 'ffmpeg') {
      // For transcoded files from FFmpeg, use WebCodecs for playback
      await this.loadVideoWithWebCodecs(buffer);
    }
  }

  /**
   * Load and transcode video using FFmpeg.wasm
   */
  private async loadVideoWithFFmpeg(source: string | ArrayBuffer | File): Promise<void> {
    if (!this.ffmpegDecoder) {
      throw new Error('FFmpeg decoder not available');
    }

    // Load video into FFmpeg
    const ffmpegMetadata = await this.ffmpegDecoder.loadVideo(source);

    // Transcode to MP4 for WebCodecs playback
    const transcoded = await this.ffmpegDecoder.transcode();

    // Store transcoded buffer (ensure it's an ArrayBuffer, not SharedArrayBuffer)
    this.transcodedBuffer = transcoded.data.slice().buffer as ArrayBuffer;

    // Update metadata from FFmpeg
    this.metadata = {
      width: transcoded.width,
      height: transcoded.height,
      duration: transcoded.duration,
      frameRate: ffmpegMetadata.frameRate || 30,
      codec: transcoded.codec,
    };

    // Set backend to ffmpeg (but use WebCodecs for actual decoding of transcoded content)
    this.backend = 'ffmpeg';

    // If WebCodecs is available, use it to play the transcoded content
    if (this.webCodecsDecoder && this.demuxer && this.transcodedBuffer) {
      await this.loadVideoWithWebCodecs(this.transcodedBuffer);
    }
  }

  /**
   * Load video using WebCodecs backend
   */
  private async loadVideoWithWebCodecs(buffer: ArrayBuffer): Promise<void> {
    if (!this.webCodecsDecoder) {
      throw new Error('WebCodecs backend not initialized');
    }

    // Reset state for new video
    this.videoSampleQueue.clear();
    this.audioSampleQueue.clear();
    this.webCodecsFrameQueue.clear();
    // Reset persistent sample storage
    this.allVideoSamples = [];
    this.allAudioSamples = [];
    this.needsKeyframe = true;

    // Reset WebCodecs decoders
    this.webCodecsDecoder.resetVideo();
    this.webCodecsDecoder.resetAudio();

    // Create fresh demuxer for new video
    if (this.demuxer) {
      this.demuxer.close();
    }
    this.demuxer = new Demuxer({
      onVideoSample: (sample: VideoSample) => {
        // Store in both queue (for playback) and persistent storage (for seeking)
        this.videoSampleQueue.push(sample);
        this.allVideoSamples.push(sample);
        // Debug: log first and every 100th sample
        if (this.allVideoSamples.length === 1 || this.allVideoSamples.length % 100 === 0) {
          log.debug('Sample stored:', this.allVideoSamples.length, 'timestamp:', sample.timestamp, 'keyframe:', sample.keyframe);
        }
      },
      onAudioSample: (sample: AudioSample) => {
        this.audioSampleQueue.push(sample);
        this.allAudioSamples.push(sample);
      },
    });
    this.demuxer.init();

    return new Promise<void>((resolve, reject) => {
      const originalOnReady = this.demuxer!['config'].onReady;

      // eslint-disable-next-line @typescript-eslint/no-explicit-any
      (this.demuxer as any).config.onReady = async (info: any) => {
        try {
          const videoTrack = info.videoTracks[0];
          if (videoTrack) {
            // Log track info for debugging
            log.debug('Video track:', {
              codec: videoTrack.codec,
              width: videoTrack.codedWidth,
              height: videoTrack.codedHeight,
              hasDescription: !!videoTrack.description,
              descriptionLength: videoTrack.description?.length,
            });

            await this.webCodecsDecoder!.initVideoDecoder({
              codec: videoTrack.codec,
              codedWidth: videoTrack.codedWidth,
              codedHeight: videoTrack.codedHeight,
              description: videoTrack.description,
            });

            // After decoder is configured, we need a keyframe
            this.needsKeyframe = true;

            this.metadata = {
              width: videoTrack.codedWidth,
              height: videoTrack.codedHeight,
              duration: info.duration,
              frameRate: videoTrack.frameRate,
              codec: videoTrack.codec,
            };
          }

          const audioTrack = info.audioTracks[0];
          if (audioTrack) {
            await this.webCodecsDecoder!.initAudioDecoder({
              codec: audioTrack.codec,
              sampleRate: audioTrack.sampleRate,
              numberOfChannels: audioTrack.numberOfChannels,
              description: audioTrack.description,
            });
          }

          originalOnReady?.(info);
          this.demuxer!.start();
          resolve();
        } catch (error) {
          reject(error);
        }
      };

      // eslint-disable-next-line @typescript-eslint/no-explicit-any
      (this.demuxer as any).config.onError = (error: Error) => {
        reject(error);
      };

      this.demuxer!.appendBuffer(buffer);
      this.demuxer!.flush();
    });
  }

  /**
   * Get video metadata
   */
  getMetadata(): VideoMetadata | null {
    return this.metadata;
  }

  /**
   * Decode the next frame
   */
  decodeFrame(): DecodedFrame | null {
    this.ensureInitialized();

    if (this.backend === 'wasm') {
      return this.wasmModule!.decode_frame();
    }

    // WebCodecs backend
    return this.decodeFrameWithWebCodecs();
  }

  /**
   * Decode frame using WebCodecs backend
   */
  private decodeFrameWithWebCodecs(): DecodedFrame | null {
    // Skip frames before seek target (they're needed for decoding but not for display)
    // Do this in a loop to avoid deep recursion
    while (this.webCodecsFrameQueue.length > 0 && this.seekTargetTimestamp > 0) {
      const frame = this.webCodecsFrameQueue.peek()!;
      if (frame.timestamp < this.seekTargetTimestamp) {
        // Skip this frame
        this.webCodecsFrameQueue.shift();
        continue;
      }
      // Found a frame at or after target
      log.debug('Seek complete: reached target, frame timestamp=', frame.timestamp, 'target=', this.seekTargetTimestamp);
      this.seekTargetTimestamp = 0;
      break;
    }

    // Process pending audio samples BEFORE returning video frame
    // This ensures audio decoding runs in parallel with video during normal playback
    this.decodeAudioSamples();

    // Return queued frame if available
    if (this.webCodecsFrameQueue.length > 0) {
      return this.webCodecsFrameQueue.shift()!;
    }

    // Check if decoder is ready
    if (!this.webCodecsDecoder || !this.webCodecsDecoder.isVideoInitialized()) {
      return null;
    }

    // Debug: log queue status when seeking (throttled to avoid spam)
    if (this.seekTargetTimestamp > 0 && this.videoSampleQueue.length % 50 === 0) {
      log.debug('Seeking: frameQueue=', this.webCodecsFrameQueue.length,
        'sampleQueue=', this.videoSampleQueue.length, 'target=', this.seekTargetTimestamp);
    }

    // Process pending video samples
    if (this.videoSampleQueue.length > 0) {
      // VideoDecoder requires a keyframe after configure/flush
      // Skip non-keyframe samples until we get a keyframe
      if (this.needsKeyframe) {
        while (this.videoSampleQueue.length > 0) {
          const sample = this.videoSampleQueue.peek()!;
          if (sample.keyframe) {
            this.needsKeyframe = false;
            break;
          }
          // Skip non-keyframe
          this.videoSampleQueue.shift();
        }

        // Still need keyframe but none found
        if (this.needsKeyframe || this.videoSampleQueue.length === 0) {
          return null;
        }
      }

      if (this.videoSampleQueue.length === 0) {
        return null;
      }

      const sample = this.videoSampleQueue.shift()!;

      // Final safety check - verify we have a keyframe when needed
      if (this.needsKeyframe && !sample.keyframe) {
        this.needsKeyframe = true;
        return null;
      }

      const chunk = Demuxer.createVideoChunk(sample);

      // Don't await - let it process asynchronously
      void this.webCodecsDecoder.decodeVideo(chunk).catch((_error: Error) => {
        // If decode fails, we need a keyframe again
        this.needsKeyframe = true;
      });

      // Try to return a frame that may have been decoded
      if (this.webCodecsFrameQueue.length > 0) {
        return this.webCodecsFrameQueue.shift()!;
      }
    }

    return null;
  }

  /**
   * Decode audio samples (called during video decoding loop)
   * Processes audio samples asynchronously and sends to AudioPlayer
   */
  private decodeAudioSamples(): void {
    // Skip if no audio decoder or audio player
    if (!this.webCodecsDecoder || !this.webCodecsDecoder.isAudioInitialized()) {
      return;
    }

    // Process multiple audio samples per frame (audio samples are much smaller than video frames)
    const maxAudioSamplesPerFrame = 10;
    let samplesProcessed = 0;

    while (this.audioSampleQueue.length > 0 && samplesProcessed < maxAudioSamplesPerFrame) {
      const sample = this.audioSampleQueue.shift()!;
      const chunk = Demuxer.createAudioChunk(sample);

      // Decode asynchronously (onAudioData callback will handle playback)
      void this.webCodecsDecoder.decodeAudio(chunk).catch((error: Error) => {
        log.error('Audio decode failed:', error);
      });

      samplesProcessed++;
    }
  }

  /**
   * Seek to a specific timestamp
   */
  async seek(timestamp: number): Promise<void> {
    this.ensureInitialized();

    if (this.backend === 'wasm') {
      const success = this.wasmModule!.seek(timestamp);
      if (!success) {
        throw new Error('Seek operation failed');
      }
    } else if (this.backend === 'webcodecs') {
      // Increment generation to invalidate in-flight frame copies
      this.seekGeneration++;

      // Flush decoders - waits for pending decodes to complete
      await this.webCodecsDecoder?.flushVideo();
      await this.webCodecsDecoder?.flushAudio();

      // Clear frame queue AFTER flush to discard any produced frames
      this.webCodecsFrameQueue.clear();

      // Need keyframe after flush
      this.needsKeyframe = true;

      // Re-populate queues from persistent storage
      // Convert timestamp from seconds to microseconds for sample comparison
      const targetTimestampUs = timestamp * 1_000_000;

      // Store seek target in SECONDS - frames before this will be decoded but skipped in output
      // (frame.timestamp is in seconds after conversion in handleWebCodecsVideoFrame)
      this.seekTargetTimestamp = timestamp;

      // Find the keyframe at or before the target time
      let keyframeIndex = 0;
      for (let i = this.allVideoSamples.length - 1; i >= 0; i--) {
        if (this.allVideoSamples[i]!.keyframe && this.allVideoSamples[i]!.timestamp <= targetTimestampUs) {
          keyframeIndex = i;
          break;
        }
      }

      log.debug('seek: target=', timestamp, 's',
        'keyframeIndex=', keyframeIndex, 'totalSamples=', this.allVideoSamples.length);

      // Re-populate video queue from keyframe
      this.videoSampleQueue.clear();
      for (let i = keyframeIndex; i < this.allVideoSamples.length; i++) {
        this.videoSampleQueue.push(this.allVideoSamples[i]);
      }

      // For audio, find samples at or after target time
      this.audioSampleQueue.clear();
      const audioStartIndex = this.allAudioSamples.findIndex(s => s.timestamp >= targetTimestampUs);
      if (audioStartIndex >= 0) {
        for (let i = audioStartIndex; i < this.allAudioSamples.length; i++) {
          this.audioSampleQueue.push(this.allAudioSamples[i]);
        }
      }

      log.debug('seek: videoQueue=', this.videoSampleQueue.length,
        'audioQueue=', this.audioSampleQueue.length);
    }
  }

  /**
   * Flush decoder buffers
   */
  flush(): void {
    this.ensureInitialized();

    if (this.backend === 'wasm') {
      this.wasmModule!.flush();
    } else if (this.backend === 'webcodecs') {
      void this.webCodecsDecoder?.flushVideo();
      void this.webCodecsDecoder?.flushAudio();
    }
  }

  /**
   * Check if samples are exhausted and need reload
   */
  needsSampleReload(): boolean {
    if (this.backend !== 'webcodecs') {
      return false;
    }
    return this.videoSampleQueue.length === 0 && this.webCodecsFrameQueue.length === 0;
  }

  /**
   * Reload samples at current or specified position
   */
  async reloadSamples(timestamp: number): Promise<void> {
    if (this.backend !== 'webcodecs') {
      return;
    }
    await this.seek(timestamp);
  }

  /**
   * Check if FFmpeg transcoding is available
   */
  isFFmpegAvailable(): boolean {
    return this.ffmpegDecoder !== null && this.ffmpegDecoder.isLoaded();
  }

  /**
   * Get FFmpeg decoder for advanced operations
   * Returns null if FFmpeg is not available
   */
  getFFmpegDecoder(): FFmpegDecoder | null {
    return this.ffmpegDecoder;
  }

  /**
   * Clean up resources
   */
  dispose(): void {
    if (this.wasmModule) {
      this.wasmModule.free();
      this.wasmModule = null;
    }

    if (this.webCodecsDecoder) {
      this.webCodecsDecoder.close();
      this.webCodecsDecoder = null;
    }

    if (this.ffmpegDecoder) {
      void this.ffmpegDecoder.dispose();
      this.ffmpegDecoder = null;
    }

    if (this.demuxer) {
      this.demuxer.close();
      this.demuxer = null;
    }

    this.videoSampleQueue.clear();
    this.audioSampleQueue.clear();
    this.webCodecsFrameQueue.clear();
    this.transcodedBuffer = null;
    this.initialized = false;
    this.metadata = null;
    this.backend = 'none';
  }

  /**
   * Ensure decoder is initialized
   */
  private ensureInitialized(): void {
    if (!this.initialized) {
      throw new Error('Decoder not initialized. Call init() first.');
    }
  }
}
